# CI_Project

This project implements a simple neural network library from scratch using Python and NumPy, and demonstrates its functionality by solving the classic XOR problem. The repository contains a lib/ folder with all library code, including layers.py (Dense layers), activations.py (Tanh, Sigmoid, ReLU), network.py (Sequential/Network class), losses.py (Mean Squared Error loss), and optimizer.py (Stochastic Gradient Descent). The notebooks/ folder contains xor_demo.ipynb, a Jupyter notebook that trains the network on the XOR dataset, plots the training loss curve, and prints predictions. The project requires Python 3.x, NumPy, Matplotlib, and Jupyter Notebook (or VS Code with Jupyter extension). To run, open xor_demo.ipynb and execute all cells sequentially; after training, expected output shows the loss decreasing and XOR predictions close to [0,1,1,0]. This library implements forward and backward propagation, modular layers, activations, loss, and optimizer in a beginner-friendly way, validating correctness through the XOR demo.
